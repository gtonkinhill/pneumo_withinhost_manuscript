---
title: "Antimicrobial treatment pairwise GWAS"
author: "Gerry Tonkin-Hill"
date: "`r Sys.Date()`"
output: 
  html_document:
    fig_width: 12
    fig_height: 8
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.width=20, fig.height=12,
                      echo=TRUE, warning=FALSE, message=FALSE,
                      tidy=TRUE)
options(stringsAsFactors = FALSE)
```
  
##Load Libraries

```{r}
library(data.table)
library(tidyverse)
library(broom)
library(ggrepel)
library(ggthemes)
library(scales)
library(parallel)
library(pbapply)
library(lubridate)
```


##Build Unitig Count Matrix

Building the unitig count matrix required significant computational resources. As such this section only provides the commands used to generate the unitig count matrix and is not set up to be run from Rmarkdown.

We initially run the DSK (v2.2.0) kmer counting tool to reduce the size of the data set we input to Bifrost.

```
while read folder; do
  r1=${folder}/*_1.fastq.gz
  r2=${folder}/*_2.fastq.gz
  prefix=$(basename $r1)
  prefix="${prefix/_1.fastq.gz/}"
  echo ./scripts/count_kmers.sh -1 $r1 -2 $r2 -p $prefix -t 5 >> kmer_count_cmds.txt
done < fastq_file_locs.txt

parallel -j 6 --progress < kmer_count_cmds.txt
```

We only consider those samples that have passed our initial quality control thresholds.

```{r, eval=FALSE}
manifests_qc <- fread("./data/manifest_w_QC.csv", data.table = FALSE)
write.table(paste("./unitig_counts/kmer_counts/", 
                  paste(manifests_qc$`Lane Name`, "_kmers.fasta.gz", sep = ""), sep = ""),
            file = "kmer_count_files_qc.txt", col.names = FALSE, row.names = FALSE, quote = FALSE)
```

By running Bifrost (v0.2) to generate unitigs instead of kmers we can dramatically reduce the number of features we need to consider when performing the GWAS analysis. This approach was initially proposed in https://doi.org/10.1371/journal.pgen.1007758

```
bsub.py --threads 52 -q long 80 run_bifrost ./bifrost/build/src/Bifrost build -r kmer_count_files_qc.txt -o unitig_bifrost -t 52 -v -a

Bifrost build -r kmer_count_files_qc.txt -o unitig_bifrost -t 24 -v -a
```

Once we have the final set of unique unitigs we then need to count the number of times they appear in each file and combine these counts into a single matrix for downstream analysis.

```
bsub -q long -n 2 -R "span[hosts=1]" -M 90000 -R "select[mem>90000] rusage[mem=90000]" -o combine_count.o -e combine_count.e python ./scripts/summarise_unitig_counts2.py --unitig ./data/unitig_bifrost.fasta --kmers ./data/kmer_count_files_qc.txt -o all_counts/ -t 2 -K 31

python ./scripts/summarise_unitig_counts2.py --unitig ./bifrost_run/unitig_bifrost.fasta --kmers ./kmer_count_files_qc.txt -o all_counts/ -t 2 -K 31

paste -d "," ./all_counts/*.csv > combined_counts.txt
```

##Load epidemiological data and CDC resistance calls

```{r}
CDC_resistance <- fread("./data/TABLE_SPN_CDC_v1.0.3_output_20200527_Typing_Results.txt", 
                        data.table = FALSE, sep="\t", fill=TRUE) %>% as_tibble()
manifests_qc <- fread("./data/manifest_w_QC.csv", data.table = FALSE) %>% as_tibble()
ena_accessesions <- fread("./data/pneumoDEEP_accessions.csv", data.table = FALSE, 
                          header = FALSE, col.names = c("lane", "ena_acc")) %>% as_tibble()
swab_summary <- fread("./data/epi/Pneumo-DEEP_swab_summary.csv", data.table = FALSE) %>% as_tibble
abx_summary <- fread("./data/epi/Pneumo-DEEP_illness_abx_summary.csv", data.table = FALSE) %>% as_tibble
merged_serotype_calls <- fread("./data/merged_serotype_calls.csv", data.table = FALSE) %>% as_tibble()
library_stats <- fread("./data/5000.pathfind_stats.csv", data.table = FALSE) %>% as_tibble()

conservative_carriage_estimates <- fread("./data/carriage_episode_estimates.csv", data.table = FALSE) %>% as_tibble()

merged_serotype_calls$carriage_episode <- conservative_carriage_estimates$carriage_episode[
  match(paste(merged_serotype_calls$specnum, merged_serotype_calls$GPSC),
        paste(conservative_carriage_estimates$specnum, conservative_carriage_estimates$GPSC))
]
```

Initially we assign each swab as being pre or post treatment if the swab was taken within 4 weeks of an antibiotic treatment event. Similarly we associate the diagnosis of within 4 weeks of a swab.

```{r}
swab_summary$specdate <- lubridate::as_date(swab_summary$specdate)
swab_summary$ID <- paste(swab_summary$codenum, swab_summary$category, sep = "-")

#map samples with treatment status
abx_summary$ID <- paste(abx_summary$codenum, "Infant", sep="-")
abx_summary$date_start <- lubridate::as_date(abx_summary$date_start)

#add treatment information
swab_summary$treatment <- map_chr(1:nrow(swab_summary), function(i){
  sampleID <- swab_summary$ID[[i]]
  treatments <- abx_summary[abx_summary$ID==sampleID,]
  treatments <- treatments[!is.na(treatments$drug1),]
  diff <- swab_summary$specdate[[i]]-treatments$date_start
  if (any((diff>0) & (diff<=28))){
    return("TREATED")
  } else if (any((diff>0) & (diff<60))) {
    return("AMBIGUOUS")
  } else {
    return("NOT_TREATED")
  }
})

#add diagnosis information
swab_summary$diagnosis <- map(1:nrow(swab_summary), function(i){
  sampleID <- swab_summary$ID[[i]]
  treatments <- abx_summary[abx_summary$ID==sampleID,]
  treatments <- treatments[!is.na(treatments$drug1),]
  treatments <- treatments[abs(swab_summary$specdate[[i]]-treatments$date_start)<28,, drop=FALSE]
  if (nrow(treatments)>0){
    return(unique(treatments$diagnosis_clinical))
  } else {
    return(NA)
  }
})

swab_summary <- swab_summary[!duplicated(swab_summary$specnum),]
merged_serotype_calls$treatment <- swab_summary$treatment[match(merged_serotype_calls$specnum, swab_summary$specnum)]
merged_serotype_calls$diagnosis <- swab_summary$diagnosis[match(merged_serotype_calls$specnum, swab_summary$specnum)]
merged_serotype_calls$host <- swab_summary$ID[match(merged_serotype_calls$specnum, swab_summary$specnum)]
```

We now identify pairs of sample before and after antimicrobial treatment and corresponding samples where no treatment has occurred.

```{r}
#First identify pairs of samples from the same patient that are within 6 weeks of each other.
test_pairs <- map_dfr(unique(swab_summary$ID), function(id){
  idswabs <- swab_summary[swab_summary$ID==id, , drop=FALSE]
  idswabs <- idswabs[!duplicated(idswabs$specnum), , drop=FALSE]
  if (nrow(idswabs)>1) {
    d <- as.matrix(dist(idswabs$specdate))
    diag(d) <- Inf
    pairs <- which(d<100, arr.ind = TRUE)
    map2_dfr(pairs[,1], pairs[,2], function(i,j){
      if (idswabs$specdate[[i]]>idswabs$specdate[[j]]){
        temp <- i
        i <- j
        j <- temp
      }
      tibble(idA=idswabs$ID[[i]],
             idB=idswabs$ID[[j]],
             specA=idswabs$specnum[[i]],
             specB=idswabs$specnum[[j]],
             dateA=idswabs$specdate[[i]],
             dateB=idswabs$specdate[[j]],
             time_diff=idswabs$specdate[[j]]-idswabs$specdate[[i]])
    })
  } else {
    return(NULL)
  }
})

# remove duplicates
test_pairs <- test_pairs[!duplicated(test_pairs),]

#only keep pairs who's first case was at least 2 months after treatment
abx_summary$ID <- paste(abx_summary$codenum, "Infant", sep="-")
abx_summary$date_start <- lubridate::as_date(abx_summary$date_start)

test_pairs$prev_treatment <- map_lgl(1:nrow(test_pairs), function(i){
  sub_abx <- abx_summary[abx_summary$ID==test_pairs$idA[[i]], , drop=FALSE]
  keep <- sub_abx$date_start < test_pairs$dateA[[i]]
  sub_abx <- sub_abx[keep, , drop=FALSE]
  sub_abx <- sub_abx[!is.na(sub_abx$drug1),,drop=FALSE]
  if (nrow(sub_abx)<1){
    return(FALSE)
  }
  else if ((test_pairs$dateA[[i]]-max(sub_abx$date_start, na.rm = TRUE)) < 28){
    return(TRUE)
  } else {
    return(FALSE)
  }
})

#add treatment information
test_pairs$treatment <- map(1:nrow(test_pairs), function(i){
  sub_abx <- abx_summary[abx_summary$ID==test_pairs$idA[[i]], , drop=FALSE]
  keep <- (sub_abx$date_start >= test_pairs$dateA[[i]]) & (sub_abx$date_start < test_pairs$dateB[[i]])
  sub_abx <- sub_abx[keep, , drop=FALSE]
  sub_abx <- sub_abx[!is.na(sub_abx$drug1),,drop=FALSE]
  return(map_dfr(1:nrow(sub_abx), function(j){
    drugs <- unlist(sub_abx[j, c("drug1", "drug2", "drug3", "drug4")])
    drugs <- drugs[!is.na(drugs)]
    drugs <- map_dfr(drugs, ~ tibble(date=sub_abx$date_start[[j]], drug=.x))
  }))
})
test_pairs$is_treated <- map_lgl(test_pairs$treatment, ~ nrow(.x)>0)
test_pairs <- test_pairs[!test_pairs$prev_treatment,]

#remove those pairs where the follow up sample was too far from treatment
test_pairs$is_follow_up <- map_lgl(1:nrow(test_pairs), function(i){
  if (!test_pairs$is_treated[[i]]){
    return(TRUE)
  } else if ((test_pairs$dateB[[i]] - max(test_pairs$treatment[[i]]$date))<=28){
    return(TRUE)
  } else {
    return(FALSE)
  }
})
test_pairs <- test_pairs[test_pairs$is_follow_up,]

test_pairs <- test_pairs[order(test_pairs$specA, test_pairs$time_diff),]
test_pairs <- test_pairs[!duplicated(test_pairs$specA), ]
test_pairs <- test_pairs[order(test_pairs$specB, test_pairs$time_diff),]
test_pairs <- test_pairs[!duplicated(test_pairs$specB), ]

specs_to_keep <- (merged_serotype_calls %>% 
  filter(!is.na(consensus_percentage)) %>%
  filter(grepl("Infant", host)))$specnum


test_pairs <- test_pairs %>% 
  filter(specA %in% specs_to_keep) %>%
  filter(specB %in% specs_to_keep)

test_pairs$pair <- paste(test_pairs$specA, test_pairs$specB, sep="_")
test_pairs$treatment <- map_chr(test_pairs$treatment, ~ paste(unlist(.x), collapse = "/"))
write.csv(test_pairs, file="data/test_pairs_treatment_association.csv", row.names = FALSE, quote = FALSE)
```

## Lineage level

```{r}
lineage_calls <- merged_serotype_calls %>%
    filter(!is.na(msweep_percentage)) %>%
    filter(!is.na(consensus_percentage)) %>%
    filter(grepl("Infant", host)) 

tests <- map_dfr(unique(lineage_calls$GPSC), ~{
  print(.x)
  
  dat <- test_pairs
  gpsc_lineage_calls <- lineage_calls %>% filter(GPSC==.x)
  
  dat$freqA <- gpsc_lineage_calls$consensus_percentage[match(dat$specA,gpsc_lineage_calls$specnum)]/100
  dat$freqB <- gpsc_lineage_calls$consensus_percentage[match(dat$specB,gpsc_lineage_calls$specnum)]/100
  dat$freqA[is.na(dat$freqA)] <- 0
  dat$freqB[is.na(dat$freqB)] <- 0
  dat$presA <- dat$freqA>0
  dat$presB <- dat$freqB>0
  
  dat2 <- dat %>% filter((presA+presB)>0)  
  if (length(unique(dat2$is_treated))<=1) return(tibble())
  if (nrow(dat2)<5) return(tibble())
  
  m <- glm(presB ~ time_diff + presA +is_treated, family=binomial, data = dat)
  conv <- m$converged
  m <- broom::tidy(m) %>% 
    filter(term=='is_treatedTRUE') %>%
    add_column(gpsc=.x, .before = 1)
  m$term <- NULL
  m$converged <- conv
  m$binary_model <- TRUE
  
  m2 <- glm(freqB ~ time_diff + freqA +is_treated, family=quasibinomial, data = dat2)
  conv <- m2$converged
  m2 <- broom::tidy(m2) %>% 
    filter(term=='is_treatedTRUE') %>%
    add_column(gpsc=.x, .before = 1)
  m2$term <- NULL
  m2$converged <- conv
  m2$binary_model <- FALSE
  
  return(rbind(m, m2))
}) %>% 
  filter(converged) %>%
  arrange(p.value)

prop_tests <- tests %>% filter(!binary_model)
prop_tests$adj.p.value <- p.adjust(prop_tests$p.value, method = 'BH')

logistic_tests <- tests %>% filter(binary_model)
logistic_tests$adj.p.value <- p.adjust(logistic_tests$p.value, method = 'BH')



pdf <- test_pairs
gpsc_lineage_calls <- lineage_calls %>% filter(GPSC==1)
pdf$freqA <- gpsc_lineage_calls$consensus_percentage[match(pdf$specA,gpsc_lineage_calls$specnum)]/100
pdf$freqB <- gpsc_lineage_calls$consensus_percentage[match(pdf$specB,gpsc_lineage_calls$specnum)]/100
pdf$freqA[is.na(pdf$freqA)] <- 0
pdf$freqB[is.na(pdf$freqB)] <- 0
pdf <- pdf %>% filter(freqA+freqB >0)


pdf2 <- tibble(
  freq = (pdf$freqB -pdf$freqA)*100,
  pair = pdf$pair, 2,
  treated = ifelse(pdf$is_treated, 'Treated', 'Not Treated')
)

ggplot(pdf2, aes(x=treated, y=freq, col=treated)) +
  geom_boxplot(outlier.colour = NA) +
  ggbeeswarm::geom_quasirandom(varwidth = TRUE, width = 0.2) +
  theme_clean(base_size = 20) +
  scale_colour_manual(values = c('#0571b0', '#ca0020')) +
  theme(plot.background = element_blank(),
        legend.background = element_blank(),
        strip.text.y = element_blank(),
        legend.position = 'none') +
  ylab('Change in frequency') +
  xlab('')

ggsave("figures/gpsc1_treatment_boxplot.png", width = 10, height = 7)
ggsave("figures/gpsc1_treatment_boxplot.pdf", width = 10, height = 7)
```


```{r}
pdf <- test_pairs[,-c(1,2,5,6,7,9,11)] %>% 
  pivot_longer(cols=c('specA','specB'))
pdf$name <- factor(ifelse(pdf$name=='specA', 'pre','post'), levels = c('pre','post'))


pdf <- map_dfr(1:nrow(pdf), ~{
  gpsc <- lineage_calls$GPSC[lineage_calls$specnum==pdf$value[[.x]]]
  return(tibble(
    pair=pdf$pair[[.x]],
    prepost=pdf$name[[.x]],
    is_treated=pdf$is_treated[[.x]],
    GPSC=gpsc,
    freq=lineage_calls$consensus_percentage[match(paste(pdf$value[[.x]], gpsc),
                                                       paste(lineage_calls$specnum, lineage_calls$GPSC)
                                                       )]/100
  ))
})
pdf$GPSC <- factor(pdf$GPSC)
pdf$is_treated <- ifelse(pdf$is_treated, 'Treated', 'Not Treated')

tb <- sort(table(pdf$GPSC), decreasing = TRUE)

pdf2 <- pdf %>% pivot_wider(values_from='freq', names_from = 'prepost')
pdf2$pre <- map_dbl(pdf2$pre, ~ ifelse(length(.x)>0, .x, 0))
pdf2$post <- map_dbl(pdf2$post, ~ ifelse(length(.x)>0, .x, 0))

tb <- table(pdf2$is_treated, pdf2$GPSC)

pdf2 <- pdf2 %>% filter(GPSC %in% colnames(tb)[colSums(tb>1)==2])

pdf2$diff <- pdf2$pre-pdf2$post

pdf2 <- pdf2 %>% 
  group_by(is_treated, GPSC) %>%
  summarise(
    diff=mean(diff, na.rm = T)
  )

pdf2 <- pdf2 %>% pivot_wider(values_from='diff', names_from = 'is_treated')
  
ggplot(pdf2) +
  geom_segment( aes(x=GPSC, xend=GPSC, y=`Not Treated`, yend=Treated), color="grey") +
  geom_point( aes(x=GPSC, y=`Not Treated`), color='#ca0020', size=3 ) +
  geom_point( aes(x=GPSC, y=Treated), color='#0571b0', size=3 ) +
  theme_clean(base_size = 20) +
    theme(plot.background = element_blank(),
          legend.background = element_blank(),
          legend.position = 'none') +
  coord_flip() +
  xlab("GPSC") + ylab("Lineage prevalence (%)")




tba <- sort(table(merged_serotype_calls$GPSC), decreasing = TRUE)

pdf <- merged_serotype_calls
pdf$is_treated <- pdf$treatment=="TREATED"
tb <- table(pdf$is_treated, pdf$GPSC)

pdf <- tibble(
  GPSC=colnames(tb),
  treated=tb[2,]/sum(tb[2,])*100,
  not_treated=tb[1,]/sum(tb[1,])*100
) 

pdf <- pdf %>% filter(GPSC %in% names(tba)[colSums(tb)/sum(tb)>=0.01])
pdf$GPSC <- factor(pdf$GPSC, levels = pdf$GPSC[order(pdf$treated)])

ggplot(pdf) +
  geom_segment( aes(x=GPSC, xend=GPSC, y=treated, yend=not_treated), color="grey") +
  geom_point( aes(x=GPSC, y=treated), color='#ca0020', size=3 ) +
  geom_point( aes(x=GPSC, y=not_treated), color='#0571b0', size=3 ) +
  theme_clean(base_size = 20) +
    theme(plot.background = element_blank(),
          legend.background = element_blank(),
          legend.position = 'none') +
  coord_flip() +
  xlab("GPSC") + ylab("Lineage prevalence (%)")

ggsave("figures/lollipop_lineage_treatment_fractions.png", width = 10, height = 7)
ggsave("figures/lollipop_lineage_treatment_fractions.pdf", width = 10, height = 7)
```

## Locus level

Unlike the paired analysis of GPSC and serotype frequencies we further filter pairs into those where the same GPSC is present both before and after treatment.

```{r}
merged_serotype_calls <- fread("./data/merged_serotype_calls.csv", data.table = FALSE) %>% as_tibble() %>%
  filter(!is.na(GPSC))

test_pairs$GPSC_A <- map(test_pairs$specA, ~ unique(merged_serotype_calls$GPSC[merged_serotype_calls$specnum==.x]))
test_pairs$GPSC_B <- map(test_pairs$specB, ~ unique(merged_serotype_calls$GPSC[merged_serotype_calls$specnum==.x]))
test_pairs <- test_pairs[map2_lgl(test_pairs$GPSC_A, test_pairs$GPSC_B, ~ any(.x %in% .y)),]

allspecs <- unique(c(test_pairs$specA, test_pairs$specB))

#list count files we would like to keep
sink("keep.txt")
cat(paste(paste(manifests_qc$`Lane Name`[manifests_qc$`DONOR ID (required for EGA)` %in% allspecs], "kmers", sep="_"), collapse = ","))
sink()

test_pairs$GPSC_A <- map_chr(test_pairs$GPSC_A, ~ paste(.x, collapse = ";"))
test_pairs$GPSC_B <- map_chr(test_pairs$GPSC_B, ~ paste(.x, collapse = ";"))
write.csv(test_pairs, file = "./data/test_pairs_treatment_association_filt.csv", row.names = FALSE, quote = FALSE)


libstats <- fread("./data/5000.pathfind_stats.csv") %>% as_tibble()
libstats$specnum <- manifests_qc$`DONOR ID (required for EGA)`[match(libstats$`Lane Name`,
                                                                     manifests_qc$`Lane Name`)]
test_pairs$lib_sizeA <- libstats$Reads[match(test_pairs$specA, libstats$specnum)]
test_pairs$lib_sizeB <- libstats$Reads[match(test_pairs$specB, libstats$specnum)]
write.csv(test_pairs, file="./data/test_pairs_treatment_association_carriage_filt_libsize.csv",
          row.names = FALSE, quote = FALSE)
```
  
To concentrate on the most informative unitigs we filter out those that are found in less than 10 samples. This is achieved by initially splitting the file into chunks to allow for the filtering to be done in parallel.
  
```{python, eval=FALSE}
import numpy as np
from joblib import Parallel, delayed
import glob

split_size = 500000
split_count = 0

outfile=open("combined_counts_split" + str(split_count) + ".csv", 'w')
with open('combined_counts.csv') as file:
    header = next(file)
    for i,line in enumerate(file):
        if i % split_size==0:
            outfile.close()
            outfile=open("combined_counts_split" + str(split_count) + ".csv", 'w')
            outfile.write("unitigID,"+header)
            split_count += 1
        o=outfile.write(str(i)+","+line)
        
with open("keep.txt", 'r') as infile:
    keep=set(next(infile).strip().split(","))

n_cpu = 60
files = glob.glob("combined_counts_split*")

def trim(file):
    with open("trim_"+file, 'w') as outfile:
        with open(file, 'r') as infile:
            keep_index = [0]
            header = np.array(next(infile).strip().split(","))
            for i,h in enumerate(header):
                if h in keep:
                    keep_index.append(i)
            keep_index=np.array(keep_index)
            outfile.write(",".join(header[keep_index])+"\n")
            for i,line in enumerate(infile):
                #if i%100000==0: print(i)
                line = np.fromstring(line.strip(), dtype=int, sep=',')
                line = line[keep_index]
                if np.sum(line[1:]>3)<10: continue
                o=outfile.write(",".join([str(c) for c in line])+"\n")


res = Parallel(n_jobs=n_cpu)(
                delayed(trim)(f)
                for f in files)
```

Combine the separated files back into a single count matrix

```{bash, eval=FALSE}
xsv cat rows trim_combined_counts_split*.csv > combined_counts_filtered_min10_inpairs.csv
xsv index combined_counts_filtered_min10_inpairs.csv
xsv split -s 10000 combined_counts_filtered_min10_inpairs_split combined_counts_filtered_min10_inpairs.csv
```

##Running the GWAS

To perform the GWAS we use a linear model after first calculating the log of the unitig counts per million reads. Taking the log of the counts normalised for library size is a common practice in the analysis of RNA sequencing studies. It can be calculated as

$$\log\left( \frac{1+U_{i,j}}{N_i} \right)$$
where $U_{i,j}$ is the count of unitig $i$ in sample $j$ and $N_i$ is the number of sequencing reads in sample $j$. A one is added to account for zero counts.

A linear model can then be fit for each pre and post treatment pair. We make use of the ANCOVA method for analysing pre and post treatment data and use the pre-treatment count to control for the paired nature of the data as has been previously recommended (O'Connell et al., 2017). We also include a covariate to control for the time between when the samples were taken.

The final model for each unitig $i$ and pair $j$ where $\tau_i = 1$ if the pair involves antibiotic treatment can be written as

$$\log\left( \frac{1+U_{i,j,\text{post}}}{N_i} \right) = \beta_0 + \beta_1 \log\left( \frac{1+U_{i,j,\text{pre}}}{N_i} \right) + \beta_2 t_i + \beta_3 \tau_i + \epsilon_i$$
For each unitig we only consider those pairs for which the unitig has been found in at least one sample. We correct for multiple testing using both the conservative Bonferroni correction method which controls the family wise error rate (FWER) and the slightly less conservative Benjamini-Yekutieli method which controls the false discovery rate (FDR) allowing for dependence between tests.

```{r, eval=FALSE}
library(purrr)
library(dplyr)
library(parallel)

unitig_files <- Sys.glob("./combined_counts_filtered_min10_inpairs_split/*.csv")

Sys.setenv("OMP_NUM_THREADS" = 1)

ncpu <- 120
cl <- makePSOCKcluster(ncpu)

pairwise_gwas_results <- parallel::parLapplyLB(cl, unitig_files, function(file){
    Sys.setenv("OMP_NUM_THREADS" = 1)
    library(data.table)
    library(tibble)
    library(purrr)
    library(dplyr)
    library(edgeR)

    manifests_qc <- fread("./data/manifest_w_QC.csv", data.table = FALSE) %>% as_tibble()
    pairs <- fread(file="./data/test_pairs_treatment_association_carriage_filt_libsize.csv",
                   data.table=FALSE)
    
    unitig <- fread(file, data.table = FALSE) %>% as_tibble()
    col_specnums <- manifests_qc$`DONOR ID (required for EGA)`[
      match(gsub("_kmers", "", colnames(unitig)), manifests_qc$`Lane Name`)]
    
    indexA <- match(pairs$specA, col_specnums)
    indexB <- match(pairs$specB, col_specnums)
    
    dat <- tibble(sample=c(pairs$specA, pairs$specB),
                  pair=rep(pairs$pair, 2),
                  lib_size=c(pairs$lib_sizeA, pairs$lib_sizeB),
                  is_treated=c(pairs$is_treated, pairs$is_treated),
                  time=c(rep(0,nrow(pairs)), pairs$time_diff),
                  pre_post=c(rep('pre', nrow(pairs)), rep('post', nrow(pairs))))

    lcounts <- as.matrix(cbind(unitig[,indexA], unitig[,indexB]))
    rownames(lcounts) <- unitig$unitigID
    colnames(lcounts) <- dat$sample
    k <- (rowSums(lcounts[,dat$is_treated]>0)>4) & (rowSums(lcounts[,!dat$is_treated]>0)>4)
    lcounts <- lcounts[k,]
    lcpm <- edgeR::cpm(lcounts, log=TRUE, prior.count=1, lib.size = dat$lib_size)

    results <- map_dfr(1:nrow(lcounts), ~{

      tdat <- dat
      tdat$count <- lcounts[.x, ]
      tdat$lcpm <- lcpm[.x, ]
      
      tdat <- tdat %>% group_by(pair) %>%
        summarise(
          final = lcpm[which.max(time)],
          initial = lcpm[which.min(time)],
          treated = any(is_treated),
          time = max(time),
          max_count = max(count)
        ) %>% 
        filter(max_count>0)

      m <- tryCatch({
        
        model <- lm(final ~ initial + treated + time, tdat)
        model <- broom::tidy(model)
        # tail(model)
        if (!any(model$term=="treatedTRUE")) return(tibble())
        model <- model[model$term=="treatedTRUE", , drop=FALSE] %>% as_tibble()
        model$unitigID <- rownames(lcounts)[[.x]]
        model$converged <- TRUE
        model$term <- NULL
        model$npoints <- nrow(tdat)
        model
      },
      error = function(e) {print(paste("lm error! ", e));
        tibble(estimate=NA,
               `std.error`=NA,
               `statistic`=NA,
               `p.value`=NA,
               unitigID= rownames(lcounts)[[.x]],
               npoints=nrow(dat),
               converged=FALSE)
      }
      )

      return(m)
    }) %>%
      filter(converged)
    
    return(results)
  })


uid <- '39241728'

quasi %>% filter(unitigID==uid)
linear %>% filter(unitigID==uid)

which(rownames(lcounts)==uid)
which(rownames(lcpm)==uid)
tdat <- dat
tdat$count <- lcounts[rownames(lcounts)==uid,]
tdat$lcount <- lcpm[rownames(lcpm)==uid,]
k <- (tdat %>%
              group_by(pair) %>%
              summarise(
                allzero = all(count==0)
              ) %>% 
              filter(!allzero))$pair
tdat <- tdat %>% filter(pair %in% k)


pdf <- tdat %>%
              group_by(pair) %>%
              summarise(
                diff = 1e6*(count/lib_size)[which.max(time)] - 1e6*(count/lib_size)[which.min(time)],
                treatment = any(is_treated)
              )

asinh_trans <- function(){
  scales::trans_new(name = 'asinh', transform = function(x) asinh(x), 
            inverse = function(x) sinh(x)) 
}

ggplot(pdf, aes(x=treatment, y=diff)) + 
  geom_boxplot(outlier.colour = NA) + 
  geom_jitter(height = 0, width = 0.1) +
  scale_y_continuous(trans = 'asinh')

pdf2 <- tdat
pdf2$norm_count <- 1e6*(pdf2$count/pdf2$lib_size)
pdf2$treated_pair <- pdf2$pair %in% pdf2$pair[pdf2$is_treated]

ggplot(pdf2, aes(x=time, y=count, group=pair)) + 
         geom_point() + 
         geom_line(aes(group=pair)) +
         facet_wrap(~ treated_pair, nrow = 1) 

pairwise_gwas_results <- map_dfr(pairwise_gwas_results, ~ .x) %>%
  arrange(p.value)


fwrite(pairwise_gwas_results, file="./data/pairwise_gwas_results.csv", 
       row.names = FALSE, sep = ',', quote = FALSE, col.names = TRUE)

#threshold 
pthreshold <- 5/nrow(pairwise_gwas_results)

top_pairwise <- pairwise_gwas_results %>% filter(!is.na(p.value)) %>% filter(p.value<pthreshold)
fwrite(top_pairwise, file="./data/pairwise_gwas_results_sig.csv", 
       row.names = FALSE, sep = ',', quote = FALSE, col.names = TRUE)

all_unitigs <- fread("combined_counts_filtered_min10_inpairs.csv", data.table = FALSE) %>% as_tibble()
fwrite(all_unitigs %>% filter(unitigID %in% top_pairwise$unitigID), file="./data/pairwise_unitig_counts_sig.csv", 
       row.names = FALSE, sep = ',', quote = FALSE, col.names = TRUE)
```

Taking those hits with an adjusted p-value < 0.05 we associate them with their corresponding unitig sequence. 

```{python, eval=FALSE}
import pyfastx

with open("./data/pairwise_unitig_counts_sig.csv", 'r') as infile:
  o=next(infile)
  top_unitig_ids = set()
  for line in infile:
    top_unitig_ids.add(line.split(",")[0])

with open("./data/top_unitigs.fasta", 'w') as fasta: 
  with open("./data/top_unitigs.txt", 'w') as txt:
    for h,s in pyfastx.Fasta("unitig_bifrost.fasta", build_index=False):  
      if h in top_unitig_ids:
        o=fasta.write(">"+h+"\n"+s+"\n")
        o=txt.write(s+"\n")
```

```{python, eval=FALSE}
import pyfastx
hits = {}
with open('./data/pairwise_gwas_results_sig.csv', 'r') as infile:
  header = next(infile).strip().split(',')
  header[-1] = 'lrt-pvalue'
  for line in infile:
    line=line.strip().split(',')
    hits[line[4]] = line

with open('./data/top_unitigs_seq.txt', 'w') as outfile:
  outfile.write("\t".join(header)+'\n')
  for h,s in pyfastx.Fasta("unitig_bifrost.fasta", build_index=False):
    if h in hits:
      l = hits[h]
      l[0] = s
      o=outfile.write("\t".join(l)+"\n")
```

We also make use of the Pyseer script `annotate_hits_pyseer` to identify which genes the unitigs can be found in. This relied on the annotated set of assembled genomes from Chewapreecha et al., 2014 and the *S. pneumoniae* genomes available in RefSeq. The full list used is provided in the `pyseer_references.txt` file.

```{bash, eval=FALSE}
annotate_hits_pyseer ./data/top_unitigs.txt  ./data/pyseer_references.txt ./data/annotated_counts_unitigs.txt
```

##Investigate results

```{r}
sig_count_unitigs <- fread("./data/pairwise_gwas_results_sig.csv") %>% 
  as_tibble() 
counts <- fread("./data/pairwise_unitig_counts_sig.csv") %>% 
  as_tibble()
top_unitigs <- ape::read.dna("./data/top_unitigs.fasta", 
                             format = 'fasta', as.character = TRUE)
top_unitigs <- tibble(unitigID=names(top_unitigs), unitig=str_to_upper(map_chr(
  top_unitigs, ~ paste(.x, collapse = ''))))
annotations <- fread('./data/annotated_counts_unitigs.txt',
                     header = FALSE, col.names = c('unitig','annotation'), sep='\t') %>% 
  as_tibble()

write.csv(merge(sig_count_unitigs, top_unitigs, by.x = 'unitigID', by.y = 'unitigID'), 
          file = './data/treatment_gwas_pairwise_results_sig_with_sequence.csv', 
          row.names = FALSE, quote = FALSE)

annotations <- merge(annotations, top_unitigs, by.x='unitig', by.y='unitig', all.y = TRUE) %>% 
  as_tibble()
sig_count_unitigs <- merge(sig_count_unitigs, annotations, by.x='unitigID', by.y='unitigID') %>%
  as_tibble() %>% 
  arrange(adj.p.val)
sig_count_unitigs$gene <- map_chr(str_split(sig_count_unitigs$annotation, ';'), ~ ifelse(length(.x)>1,.x[[2]], .x))

write.table(sig_count_unitigs, './data/sig_count_unitigs.tab', row.names = FALSE, quote = FALSE, col.names = TRUE, sep='\t')
```

In addition to using the `pyseer` annotation script we also manually ran BLAST to provide more detailed protein annotations. Finally, we can generate a plot of the significant unitigs separated by annotation.

```{r}
sig_count_unitigs <- fread("./data/sig_count_unitigs.tab") %>% 
  as_tibble() 


manual_annotations <- c(`7038_8#40_00014`='ABC transporter',
                        `Streptococcus_pneumoniae_Xen35_GCF_002843545_1_00083`=NA,
                        `Streptococcus_pneumoniae_TCH8431_19A_GCF_000196595_1_00593`=NA,
                        `Streptococcus_pneumoniae_SPN_XDR_SMC1710_32_GCF_003354825_1_01563`='glycoside hydrolase',
                        `Streptococcus_pneumoniae_Xen35_GCF_002843545_1_01596`='glycoside hydrolase',
                        `Streptococcus_pneumoniae_ST6011_v0.1_01460`='DNA methylase',
                        `wcaJ_1`='CpsE',
                        `saeR` = 'response regulator'
                        )

sig_count_unitigs$manual_annotation <- sig_count_unitigs$gene
k <- sig_count_unitigs$manual_annotation %in% names(manual_annotations)
sig_count_unitigs$manual_annotation[k] <- manual_annotations[sig_count_unitigs$manual_annotation[k]]

gene_hits <- sig_count_unitigs %>% 
  filter(!is.na(p.value)) %>%
  filter(!is.na(manual_annotation)) %>%
  group_by(manual_annotation) %>%
  summarise(
      avg_beta = mean(estimate),
      min_beta = min(estimate),
      max_beta = max(estimate),
      maxp = max(-log10(p.value)),
      hits = n()
  ) %>% arrange(-maxp)

pthresholds <- tibble(p.value=-log10(c(1.510404e-08, 1.510404e-07, 7.552022e-07)),
       EFD=factor(c(0.1,1,5)))

ggplot(gene_hits, aes(x=avg_beta, y=maxp, size=hits, label=manual_annotation)) +
  geom_vline(xintercept = 0, col='black', alpha=0.3, size=0.7) +
  geom_hline(aes(yintercept=p.value, col=EFD), data = pthresholds, size=0.7, linetype="dashed") +
  geom_point() +
  scale_color_manual(values = c('#de2d26','#fc9272','#fee0d2')) +
  geom_text_repel(aes(size=14), show.legend = FALSE, colour='black', box.padding = 1) +
  scale_x_continuous(limits = c(-10,10)) +
  scale_y_continuous(limits = c(6,8.5), breaks = c(6,6.5,7,7.5,8,8.5)) +
  scale_size_continuous("Number of unitigs", range=c(3,8), limits=c(0,150), breaks = c(25,50,75,100)) +
  theme_clean(base_size = 20) +
  theme(plot.background = element_blank(),
        legend.background = element_blank()) +
  xlab("Average effect size") +
  ylab("Maximum -log10(p-value)")

ggsave("./figures/pairwise_treatment_gwas_effect_vs_p.png", width = 12, height = 7)
ggsave("./figures/pairwise_treatment_gwas_effect_vs_p.pdf", width = 12, height = 7,
       useDingbats=FALSE)
```

```{r}
manifests_qc <- fread("./data/manifest_w_QC.csv", data.table = FALSE) %>% as_tibble()
pairs <- fread(file="./data/test_pairs_treatment_association_carriage_filt_libsize.csv",
               data.table=FALSE)
merged_serotype_calls <- fread("./data/merged_serotype_calls.csv", data.table = FALSE) %>% as_tibble() %>%
  filter(!is.na(GPSC))

pairs$GPSC_A <- map(pairs$specA, ~ unique(merged_serotype_calls$GPSC[merged_serotype_calls$specnum==.x]))
pairs$GPSC_B <- map(pairs$specB, ~ unique(merged_serotype_calls$GPSC[merged_serotype_calls$specnum==.x]))

dat <- tibble(sample=c(pairs$specA, pairs$specB),
              pair=rep(pairs$pair, 2),
              lib_size=c(pairs$lib_sizeA, pairs$lib_sizeB),
              is_treated=c(pairs$is_treated, pairs$is_treated),
              time=c(rep(0,nrow(pairs)), pairs$time_diff),
              pre_post=c(rep('pre', nrow(pairs)), rep('post', nrow(pairs))),
              GPSCs=c(pairs$GPSC_A, pairs$GPSC_B))

plot_unitgs <- function(uids, title=''){
  countdf <- as_tibble(t(counts[counts$unitigID %in% uids,2:ncol(counts)]))  
  colnames(countdf) <- uids
  countdf$sample <- gsub("_kmers", "", colnames(counts)[2:ncol(counts)])
  countdf$specnum <- manifests_qc$`DONOR ID (required for EGA)`[match(countdf$sample,
                                                                      manifests_qc$`Lane Name`)]
  
  plotdf <- map_dfr(uids, function(uid){
    tdat <- dat
    tdat$count <- 1e6*unlist(countdf[match(tdat$sample, 
                                           countdf$specnum),
                                     colnames(countdf)==uid])/tdat$lib_size
    k <- (tdat %>%
            group_by(pair) %>%
            summarise(
              diff = max(count)
            ) %>% 
            filter(diff>0))$pair
    tdat <- tdat %>% filter(pair %in% k)
    tdat$unitigID <- uid
    return(tdat)
  })
  plotdf$treated_pair <- c('Not treated', 'Treated')[1+plotdf$pair %in% plotdf$pair[plotdf$is_treated]]
  plotdf$GPSCs <- map_chr(plotdf$GPSCs, ~ paste(.x, collapse = ', '))
  gg <- ggplot(plotdf, aes(x=time, y=count, group=pair, label=GPSCs)) +
    geom_point() +
    geom_line(aes(group=interaction(pair,unitigID))) +
    facet_grid( ~ treated_pair) +
    theme_clean(base_size = 16) +
    # geom_text_repel(size=3) +
    theme(plot.background = element_blank(),
          legend.background = element_blank(),
          strip.text.y = element_blank()) +
    xlab('Time between samples (days)') +
    ylab('Unitig counts per million reads (CPM)') +
    ggtitle(gsub('_.*','', title))
  gg
  return(gg)
}

all_plots <- map(unique(gene_hits$manual_annotation), ~{
  uids <- (sig_count_unitigs %>%
             filter(!is.na(p.value)) %>%
             filter(!is.na(gene))%>%
             filter(manual_annotation==.x))$unitigID
  plot_unitgs(uids, .x)
})

all_plots[[3]] + all_plots[[6]]
ggsave(filename = "./figures/pbp3_CpsE.png", width = 12, height = 7, limitsize = FALSE)
ggsave(filename = "./figures/pbp3_CpsE.pdf", width = 12, height = 7, limitsize = FALSE)

pp <- patchwork::wrap_plots(all_plots, guides = 'collect') + patchwork::plot_layout(ncol = 1)
ggsave(pp, filename = "./figures/pairwise_treatment_gwas_top_prevalence_all_box.pdf", width = 12, height = 7*length(all_plots), limitsize = FALSE)
```