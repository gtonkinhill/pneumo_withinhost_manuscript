---
title: "Alignment to reference genomes and variant calling"
author: "Gerry Tonkin-Hill"
date: "`r Sys.Date()`"
output: 
  html_document:
    fig_width: 12
    fig_height: 8
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8,
                      echo=TRUE, warning=FALSE, message=FALSE,
                      tidy=TRUE)
options(stringsAsFactors = FALSE)
```

## Define reference genomes for each cluster

As the reference genome set we are using have already been filtered for low quality assemblies we align to the medoid for each GPS cluster represented in each sample. For example if we have previously identified a sample to contain both GPSC 1 and GPSC 3 we will align the sample to the medoid reference assembly for each GPSC.

To identify the medoid assembly to use as a referece for each GPSC we use Mash screen v2.1 to calculate the a pairwise distance matrix.

The following python file iterates through each GPSC and creates a pairwise distance matrix using Mash before selecting the medoid assembly. The any2fasta (v0.4.2) program is then used to convert the GFF file to fasta format.

```{bash, eval=FALSE}
python ./scripts/find_medoids.py -i ./annotations/*.gff -c ./data/themisto_gpsc_groups.tab -o ./cluster_medoids/
```

## Align to references and call variants

We now align the reads for each sample to each the representative assembly for each of the GPSC's that were identified as being present in the sample using the mSWEEP/mash pipeline.

Pysamstats is then used to count the number of reads supporting each nucleotide at each location in the reference genome. This is used later as input to the transcluster algorithm for investigating transmission.

Individual variants are called using the `lofreq_pipeline.py` pipeline which implements the approach suggested in the lofreq manual. That is we preprocess the BAM files following GATKâ€™s best practice protocol which involves: running Picard CleanSam, realigning indels and recalibrating base qualities with GATK (BQSR).

The pipeline was then run on the Sanger compute cluster using the following software versions

- samtools 1.9
- bwa 0.7.17-r1188
- picard 2.22.2
- GATK 4.1.4.1
- pysamstats 1.1.2
- lofreq 2.1.5

```{python, eval=FALSE}
import glob
import os

# load sample locations (this is specific to the compute environment)
with open('filt_fastq_file_locs.txt', 'r') as infile:
    sample_locs = {}
    for line in infile:
        sample_locs[line.strip().split('/')[-1]] = line.strip()

#load reference locations
ref_locs = {}
for f in glob.glob('cluster_medoids/*.fasta'):
    cluster = f.split('/')[-1].split('_')[0]
    ref_locs[cluster] = os.path.abspath(f)

# build command list
cmd_base = "python ./scripts/lofreq_pipeline.py -o ./data/var_calls/ -t 10"

with open('lofreq_pipe_cmds.txt' ,'w') as outfile:
    with open('gpscs_per_sample_intersect_msweep_mash.tab', 'r') as infile:
        next(infile)
        for line in infile:
            line = line.strip().split()
            sample = line[0]
            for ref_num in line[1].split(','):
                cmd = cmd_base
                cmd += ' --r1 ' + glob.glob(sample_locs[sample] + '/*_1.fastq.gz')[0]
                cmd += ' --r2 ' + glob.glob(sample_locs[sample] + '/*_2.fastq.gz')[0]
                cmd += ' --ref ' + ref_locs[ref_num]
                #print(cmd)
                o=outfile.write(cmd + '\n')
```


```
module load current/bwa/0.7.17-r1188
module load current/picard/2.22.2--0
module load current/gatk/4.1.4.1
module load current/samtools/1.9
conda activate lofreq

bsub.py --norun -q normal --threads 10 --start 1 --end 3940 10 lofreq ~/scripts/run_line.sh lofreq_pipe_cmds.txt
```



##Filter VCFs

To investigate within host selection and mutational processes we only consider those vcfs from samples to found to have only a single GPS cluster. This helps to alleviate the added complexities encountered with multiple carriage.

```{r}
library(tidyverse)
library(data.table)
library(lubridate)
```

### Load epi data

```{r}
manifests_qc <- fread("./data/manifest_w_QC.csv", data.table = FALSE) %>% as_tibble()
swab_summary <- fread("./data/epi/Pneumo-DEEP_swab_summary.csv", data.table = FALSE) %>% as_tibble
abx_summary <- fread("./data/epi/Pneumo-DEEP_illness_abx_summary.csv", data.table = FALSE) %>% as_tibble

swab_summary$specdate <- lubridate::as_date(swab_summary$specdate)
swab_summary$ID <- paste(swab_summary$codenum, swab_summary$category, sep = "-")

#map samples with treatment status
abx_summary$ID <- paste(abx_summary$codenum, "Infant", sep="-")
abx_summary$date_start <- lubridate::as_date(abx_summary$date_start)

swab_summary$treatment <- map_chr(1:nrow(swab_summary), function(i){
  sampleID <- swab_summary$ID[[i]]
  treatments <- abx_summary[abx_summary$ID==sampleID,]
  treatments <- treatments[!is.na(treatments$drug1),]
  diff <- swab_summary$specdate[[i]]-treatments$date_start
  if (any((diff>0) & (diff<=28))){
    return("TREATED")
  } else if (any((diff>0) & (diff<60))) {
    return("AMBIGUOUS")
  } else {
    return("NOT_TREATED")
  }
})

swab_summary <- swab_summary %>% filter(specnum %in% manifests_qc$`DONOR ID (required for EGA)`)
swab_summary <- merge(swab_summary, manifests_qc[,c('Lane Name', 'DONOR ID (required for EGA)')], 
                      by.x='specnum', by.y='DONOR ID (required for EGA)', all.x=TRUE)
```

```{r, eval=FALSE}
gpscs_per_sample <- fread("data/gpscs_per_sample_intersect_msweep_mash.tab") %>% as_tibble()
gpsc_to_ref <- fread("data/gpsc_to_ref.csv") %>% as_tibble()

date_and_epi_data <- map2_dfr(gpscs_per_sample$sample, gpscs_per_sample$GPCSs, ~{
  gpcs <- as.numeric(unlist(str_split(.y, ',')))
  ngpcs <- length(gpcs)
  ref <- map_chr(gpcs, function(g) paste(g, gpsc_to_ref$reference[gpsc_to_ref$gpsc==g], sep='_'))
  df <- tibble(
    ref_lane = paste(ref, .x, sep='-'),
    date = rep(swab_summary$specdate[swab_summary$`Lane Name`==.x], ngpcs),
    specnum = rep(swab_summary$specnum[swab_summary$`Lane Name`==.x], ngpcs),
    codenum = rep(swab_summary$codenum[swab_summary$`Lane Name`==.x], ngpcs),
    category = rep(swab_summary$category[swab_summary$`Lane Name`==.x], ngpcs),
    host = rep(swab_summary$ID[swab_summary$`Lane Name`==.x], ngpcs),
    lane = rep(.x, ngpcs),
    GPSCs = gpcs
  )
  return(df)
})

ngpcs <- date_and_epi_data %>% 
  group_by(specnum) %>%
  summarise(
    ngpsc=length(unique(GPSCs))
  )
keep <- ngpcs$specnum[ngpcs$ngpsc==1]
single_date_and_epi_data <- date_and_epi_data %>% filter(specnum %in% keep)

write.table(date_and_epi_data, file = './data/transmission_date_and_epi_data.csv', 
            sep=',', quote = FALSE, col.names = TRUE, row.names = FALSE)
write.csv(single_date_and_epi_data, "./data/single_date_and_epi_data.csv", quote = FALSE)
```

While we could attempt to use tools such as Kraken to filter out contaminating reads these are heavily reference dependent. Thus contaminating reads from strains not present in the reference database would still present a problem. Instead we assume that within host variation is fairly limited and occurs randomly throughout the genome. As we are using accurate reference assemblies we would thus expect true within-host variation to be spread out fairly uniformly over the reference genome. Areas of the reference with an unusually high level of variation are likely indicative of homologous regions between the reference and a contaminant. To filter out these regions we concentrate on samples with a single GPSC and use a sliding window filter similar to that employed by Gubbins to flag potentially problematic regions. 

```{python, eval=FALSE}
from collections import defaultdict
import glob
import pyfastx

with open('./data/genome_contig_lengths.csv', 'w') as outfile:
    outfile.write('genome,contig,length\n')
    for f in glob.glob('cluster_medoids/*.fasta'):
        prefix=f.split('.')[0]
        for name, seq in pyfastx.Fasta(f, build_index=False):
            outfile.write(','.join([prefix, name, str(len(seq))]) + '\n')
```

The function below is a variant of the Gubbins algorithm adapted to identify region with a high density of polymorphisms.

```{r, eval=FALSE}
library(IRanges)

filter_regions <- function(minor_vafs, genome_length, expected_null_count=1, p.threshold=0.05) {
  
  #determine null rate of polymorphisms
  nvar <- nrow(minor_vafs)
  null_rate <- nvar/genome_length
  w <- floor(expected_null_count/null_rate)
  
  nvar_adj <- sum(map_dbl(split(minor_vafs, minor_vafs$`#CHROM`), function(chrom_var,i){
    sw_vec <- map_dbl(chrom_var$POS, ~{
      sw <- sum((chrom_var$POS<=(.x+w/2)) & (chrom_var$POS>=(.x-w/2)))
      binom.test(sw, p = null_rate,  n = w, alternative = 'greater')$p.value
    })
    sum(p.adjust(sw_vec, method='BH') > p.threshold)
  }))

  null_rate <- nvar_adj/genome_length
  w <- max(1e4, floor(expected_null_count/null_rate))
  
  all_sig_vafs <- map_dfr(split(minor_vafs, minor_vafs$`#CHROM`), function(chrom_var,i){
    # Test initial regions
    sw_vec <- map_dbl(chrom_var$POS, ~{
      sw <- sum((chrom_var$POS<=(.x+w/2)) & (chrom_var$POS>=(.x-w/2)))
      binom.test(sw, p = null_rate,  n = w, alternative = 'greater')$p.value
    })
    chrom_var$start <- ceiling(pmax(0, chrom_var$POS - w/2))
    chrom_var$end <- floor(chrom_var$POS + w/2)

    # Merge overlapping regions
    sig_vafs <- chrom_var[p.adjust(sw_vec, method='BH') < p.threshold, , drop=FALSE] %>% arrange(POS)
    ir <- IRanges(sig_vafs$start, sig_vafs$end)
    sig_vafs$group <- subjectHits(findOverlaps(ir, reduce(ir)))
    regions <- sig_vafs %>% group_by(group) %>%
      summarise(
        start=min(start),
        end=max(end)
      )
    chrom_var$region <- map_int(chrom_var$POS, ~{
      r <- regions$group[(regions$start<=.x) & (regions$end>=.x)]
      if (length(r)<1){
        return(NA)
      } else {
        return(r)
      }
    })
    sig_vafs <- chrom_var %>% filter(!is.na(region))
      
    # refine regions
    sig_vafs <- map_dfr(split(sig_vafs, sig_vafs$region), function(regiondf){
      should_trim <- TRUE
      while(should_trim && (nrow(regiondf)>=3)){
        should_trim <- FALSE
        sr <- nrow(regiondf)
        lr <- max(regiondf$POS[[sr]] - regiondf$POS[[1]] + 1, sr)
        p1 <- sr/lr
        llkr <- dbinom(sr, lr, p1, log = TRUE) - dbinom(sr, lr, null_rate, log = TRUE)
        remove_vars <- c()
        
        # attempt trim at start
        st <- sr - 1 
        lt <- max(regiondf$POS[[sr]] - regiondf$POS[[2]] + 1, st)
        pt <- st/lt
        llkt_start <- dbinom(st, lt, pt, log = TRUE) - dbinom(st, lt, null_rate, log = TRUE)
        
        # attempt trim at end
        st <- sr - 1 
        lt <- max(regiondf$POS[[sr-1]] - regiondf$POS[[1]] + 1, st)
        pt <- st/lt
        llkt_end <- dbinom(st, lt, pt, log = TRUE) - dbinom(st, lt, null_rate, log = TRUE)
        
        if ((llkt_start>llkr) && (llkt_start>llkt_end)){
          regiondf <- regiondf[-1,,drop=FALSE]
          should_trim <- TRUE
        } else if (llkt_end>llkr){
          regiondf <- regiondf[-sr,,drop=FALSE]
          should_trim <- TRUE
        }
      }
      
      # Final test to see if region passes threshold
      sr <- nrow(regiondf)
      lr <- max(regiondf$POS[[sr]] - regiondf$POS[[1]] + 1, sr)
      p1 <- sr/lr
      if (binom.test(x = sr, n = lr, p = null_rate, alternative = 'greater')$p.value >= p.threshold/(genome_length/lr)){
        # region does not pass threshold
        regiondf <- regiondf[0,]
      }
      
      return(regiondf)
    })
    return(sig_vafs)
  })
  
  all_sig_vafs$flag <- NULL
  all_sig_vafs$start <- NULL
  all_sig_vafs$end <- NULL
  minor_vafs$flag <- NULL
  
  keep_vafs <- minor_vafs[!paste(minor_vafs$`#CHROM`, minor_vafs$POS) %in% paste(all_sig_vafs$`#CHROM`, all_sig_vafs$POS),]
  keep_vafs$region <- NA
  return(rbind(keep_vafs, all_sig_vafs))
}
```

For each vcf run the filtering algorithm and identify the tri nucleotide context of each mutation. This was run on a large server.

```{r, eval=FALSE}
single_date_and_epi_data <- fread('./data/single_date_and_epi_data.csv') %>% as_tibble()
genome_lengths <- fread('./data/genome_contig_lengths.csv') %>% as_tibble()

library(parallel)

all_vars_single_gpsc <- mclapply(single_date_and_epi_data$ref_lane, function(ref_lane){
  print(ref_lane)
  var <- fread(paste(c('./var_calls/', ref_lane, '.vcf'), collapse = '')) %>% as_tibble()
  genome <- ape::read.dna(paste(c('./cluster_medoids/', gsub('-.*', '', ref_lane), '.fasta'), collapse = ''), 
                          comment.char = '', as.character = TRUE, format = 'fasta')
  if (grepl('##', var[1,1]) | (nrow(var)<1)) return(NA)
  var$AF <- map_dbl(str_split(var$INFO, ';'), ~{ as.numeric(gsub('AF=', '', .x[[2]])) })
  var$support <- map_dbl(str_split(var$INFO, ';'), ~{ 
    sum(as.numeric(unlist(str_split_fixed(gsub('DP4=', '', .x[[4]]), ',', 4))[3:4]))
  })
  
  cons_df <- var %>% group_by(`#CHROM`, POS) %>%
    summarise(
      n=n(),
      sAF=sum(AF),
      cons = list(ALT[AF>=max(AF) & AF>(1-sAF)])
    )
  cons_df$cons <- map_chr(cons_df$cons, ~ { ifelse(length(.x)>0, str_split(.x, '')[[1]], '')})
  cons_df <- cons_df %>% filter(cons!="")
  minor_vafs <- var %>% filter(AF<0.95)
  minor_vafs$CONS <- cons_df$cons[match(paste(minor_vafs$`#CHROM`, minor_vafs$POS), paste(cons_df$`#CHROM`, cons_df$POS))]
  minor_vafs$CONS[is.na(minor_vafs$CONS)] <- minor_vafs$REF[is.na(minor_vafs$CONS)]
  
  genome <- imap(genome, ~{
    temp <- cons_df %>% filter(`#CHROM`==.y)
    .x[temp$POS] <- temp$cons
    .x <- str_to_upper(.x)
    return(.x)
  })
  
  minor_vafs$context <- map2_chr(minor_vafs$`#CHROM`, minor_vafs$POS, ~ {
    r <- genome[[.x]][(.y-1)]
    r <- str_sub(r, str_length(r), str_length(r))
    l <- str_sub(genome[[.x]][(.y+1)],1, 1)
    return(str_sub(str_flatten(c(l, genome[[.x]][.y], r)), 1, 3))
  })
  
  genome_length <- sum(genome_lengths$length[genome_lengths$genome==gsub('\\.velvet.*', '', ref_lane)])
  minor_vafs <- filter_regions(minor_vafs, genome_length, expected_null_count = 1, p.threshold = 0.05)
  fwrite(minor_vafs, paste(c('./minor_var_calls/', ref_lane, '.tab'), collapse = ''), sep = '\t')
  return(minor_vafs)
}, mc.cores = 20)
```

Load the results and generate some summary plots

```{r}
files <- Sys.glob("./data/minor_var_calls/*.tab")
all_vars_single_gpsc <- map(files, ~{fread(.x) %>% as_tibble()})

names(all_vars_single_gpsc) <- gsub("\\.tab", "", gsub(".*minor_var_calls/", "", files))

region_minor_summary <- imap_dfr(all_vars_single_gpsc, ~{
  if (is.na(.x)) return(tibble())
  return(
    tibble(
      sample=.y,
      nminor=nrow(.x),
      nregions=length(unique(.x$region)),
      nremaining=sum(is.na(.x$region) & .x$AF<0.5)
    )
  )
})

ggplot(region_minor_summary %>% filter(nremaining<500), aes(x=nremaining)) +
  geom_histogram(bins=100) +
  geom_vline(xintercept=100, col='red') +
  theme_bw(base_size = 16) +
  xlab("number of variants after filtering (truncated at 500)") +
  ylab("sample count")
ggsave("./Figures/histogram_sample_vs_filtered_variant_count.png", width = 9, height = 7)
ggsave("./Figures/histogram_sample_vs_filtered_variant_count.pdf", width = 9, height = 7)

table(region_minor_summary$nremaining<100)

plotdf <- all_vars_single_gpsc[names(all_vars_single_gpsc)=='1_19341_2#69.velvet-27425_7#185'][[1]]

plotdf <- plotdf %>% filter(`#CHROM` %in% names(table(plotdf$`#CHROM`))[table(plotdf$`#CHROM`)>5])
plotdf$region[is.na(plotdf$region)] <- 'none'
plotdf$region <- factor(plotdf$region)
plotdf$`#CHROM` <- factor(paste('contig', as.numeric(factor(plotdf$`#CHROM`))),
                          levels = paste('contig', 1:length(unique(plotdf$`#CHROM`))))
ggplot(plotdf, aes(x=POS, y=AF, colour=region)) +
  geom_jitter(alpha=0.5, width = 0, height = 0.05) +
  facet_wrap(~`#CHROM`, ncol=3) +
  theme_bw(base_size = 16) +
  ylab('Variant Allele Fraction') +
  xlab('position in contig') +
  scale_color_manual(values=c('#e41a1c','#377eb8','#4daf4a','#984ea3','#636363')) +
  # scale_x_continuous(labels = function(x) format(x, scientific = TRUE, digits = 2), guide = guide_axis(n.dodge = 2)) +
  theme(axis.text.x = element_text(size = 12, angle = 45, hjust = 1))
ggsave("./Figures/binomial_filter_example.pdf", width = 9, height = 12)
ggsave("./Figures/binomial_filter_example.png", width = 9, height = 12)
```

Create a final filtered list of mutations after re-ordering to ensure that the majority allele is treated as the ancestral variant. This is an approximation that assumes a relatively tight bottleneck during transmission and that the majority of variants will remain at low frequencies.

Informed by the previous histogram we also ignore samples with more than 100 polymorphisms to avoid including sample with multiple carriage of different strains. 

```{r, eval=FALSE}
only_minority_single_gpsc <- imap_dfr(all_vars_single_gpsc, function(minor_vafs, sample){
  minor_vafs <- minor_vafs[map2_lgl(minor_vafs$REF, minor_vafs$ALT, ~{ all(str_length(c(.x, .y))==1)}),]
  minor_vafs$ref_forward <- map_dbl(str_split(minor_vafs$INFO, ';'), ~{
    sum(as.numeric(unlist(str_split_fixed(gsub('DP4=', '', .x[[4]]), ',', 4))[[1]]))
  })
  minor_vafs$ref_reverse <- map_dbl(str_split(minor_vafs$INFO, ';'), ~{
    sum(as.numeric(unlist(str_split_fixed(gsub('DP4=', '', .x[[4]]), ',', 4))[[2]]))
  })

  minor_vafs$alt_forward <- map_dbl(str_split(minor_vafs$INFO, ';'), ~{
    sum(as.numeric(unlist(str_split_fixed(gsub('DP4=', '', .x[[4]]), ',', 4))[[3]]))
  })
  minor_vafs$alt_reverse <- map_dbl(str_split(minor_vafs$INFO, ';'), ~{
    sum(as.numeric(unlist(str_split_fixed(gsub('DP4=', '', .x[[4]]), ',', 4))[[4]]))
  })

  minor_vafs$depth <- map_dbl(str_split(minor_vafs$INFO, ';'), ~{
    sum(as.numeric(gsub('DP=', '', .x[[1]]))[[1]])
  })
  minor_vafs$ref_support <- minor_vafs$ref_forward+minor_vafs$ref_reverse
  minor_vafs$alt_support <- minor_vafs$alt_forward+minor_vafs$alt_reverse

  # Swap reference to mutation when the consensus is not a reference
  minor_vafs <- minor_vafs %>% add_column(sample=sample, .before = 1)
  minor_vafs$MUT <- minor_vafs$ALT
  minor_vafs$MUT[minor_vafs$ALT==minor_vafs$CONS] <- minor_vafs$REF[minor_vafs$ALT==minor_vafs$CONS]
  minor_vafs <- minor_vafs %>%
    filter(!((MUT==REF) & ((ref_forward==0) | (ref_reverse==0) | (
      ref_support<10) ))) %>%
     filter((ref_support/depth)>0)

   minor_vafs <- minor_vafs %>%
     filter(!((MUT!=REF) & ((alt_forward==0) | (alt_reverse==0) | (
       alt_support<10) ))) %>%
     filter((alt_support/depth)>0)

   minor_vafs$AF <- map_dbl(str_split(minor_vafs$INFO, ';'), ~{ as.numeric(gsub('AF=', '', .x[[2]])) })
   swp <- minor_vafs$MUT==minor_vafs$REF
   minor_vafs$AF[swp] <- minor_vafs$ref_support[swp]/minor_vafs$depth[swp]
   
   minor_vafs$support <- minor_vafs$alt_support
   minor_vafs$support[swp] <- minor_vafs$ref_support[swp]
   
  return(minor_vafs)
})

only_minority_single_gpsc$lane <- gsub('.*-', '', only_minority_single_gpsc$sample)
only_minority_single_gpsc$ref <- gsub('-.*', '', only_minority_single_gpsc$sample)
only_minority_single_gpsc$chrom <- paste(only_minority_single_gpsc$`#CHROM`, only_minority_single_gpsc$ref, sep='-')
only_minority_single_gpsc$specnum <- swab_summary$specnum[match(only_minority_single_gpsc$lane, swab_summary$`Lane Name`)]
only_minority_single_gpsc$host <- swab_summary$ID[match(only_minority_single_gpsc$lane, swab_summary$`Lane Name`)]

#filter to the reliable samples
only_minority_single_gpsc_filt <- only_minority_single_gpsc %>% 
  filter(sample %in% region_minor_summary$sample[region_minor_summary$nremaining<100])
fwrite(only_minority_single_gpsc_filt, "./data/only_minority_single_gpsc.tab", sep = '\t')

# only count the same mutation once per host
only_minority_single_gpsc_filt <- only_minority_single_gpsc_filt[order(only_minority_single_gpsc_filt$region, na.last = FALSE),]
only_minority_single_gpsc_dedup <- only_minority_single_gpsc_filt[!duplicated(only_minority_single_gpsc_filt[,c('chrom', 'POS', 'CONS', 'MUT', 'host')]),]

fwrite(only_minority_single_gpsc_dedup, "./data/only_minority_single_gpsc_dedup.tab", sep='\t', quote = FALSE)
```

We can investigate which genes are outliers in frequently having a high density of polymorphisms

```{r}
only_minority_single_gpsc_filt <- fread("./data/only_minority_single_gpsc.tab") %>% as_tibble()
only_minority_single_gpsc_dedup <- fread("./data/only_minority_single_gpsc_dedup.tab") %>% as_tibble()

all_filt <- map_dfr(unique(only_minority_single_gpsc_filt$ref), ~{
  print(.x)
  single_ref_muts <- only_minority_single_gpsc_filt %>%
    filter(!is.na(region)) %>%
    filter(ref==.x) 
  single_ref_muts <- single_ref_muts[!duplicated(single_ref_muts[,c('host','POS','#CHROM')]),]
  
  refdb <- readRDS(paste0(c("./data/cluster_medoids/", .x, "_refcds.RDS"), collapse = ""))
  genedb <- map_dfr(refdb$RefCDS, function(g) {
    interval <- sort(c(g$intervals_cds))
    return(tibble(gene=g$gene_name,
           chrom=g$chr,
           left=interval[[1]],
           right=interval[[2]]))
    })
  
  genes <- map2(single_ref_muts$POS, single_ref_muts$`#CHROM`, 
                function(p, chrom){
                  g <- genedb$gene[(genedb$left<=p) & (genedb$right>=p) & (genedb$chrom==chrom)]
                  if (length(g)>0) return(g[[1]])
                  return("")
                })
  
  genedf <- map_dfr(1:nrow(single_ref_muts), function(i) {
    h <- single_ref_muts$host[[i]]
    g <- genes[[i]]
    tibble(host=rep(h, length(g)),
           sample=single_ref_muts$sample[[i]],
           gene=g,
           nhits=sum((genes==g) & (single_ref_muts$sample==single_ref_muts$sample[[i]]))
           )
  })
  
  med_cov <- map_dbl(split(single_ref_muts$depth,  single_ref_muts$sample), median)
  
  genedf$cov <- map_dbl(genedf$gene, function(g) mean(single_ref_muts$depth[genedf$gene==g]))
  genedf$cov_multi <- genedf$cov/med_cov[genedf$sample]
  genedf <- genedf[!duplicated(genedf[,c('host','gene')]),,drop=FALSE]
  
  return(genedf)
})

all_filt_u <- all_filt %>% filter(nhits>=3)
all_filt_u <- all_filt_u[!duplicated(all_filt_u[,c(1,2)]),]


all_filt_u <- sort(table(all_filt_u$gene), decreasing = TRUE)
all_filt_known <- all_filt_u[!grepl('unknown',names(all_filt_u))]

q <- quantile(all_filt_u, c(0.25, 0.75))
outlier_threshold <- q[[2]] + (q[[2]]-q[[1]])
top_filt_hits <- all_filt_known[all_filt_known>2]

only_minority_single_gpsc_filt %>%
  filter()

plotdf <- all_filt %>% 
  filter(gene %in% names(top_filt_hits)) %>%
  filter(gene!='')

write.csv(top_filt_hits, file='./data/commonly_filtered_genes.csv', 
          quote = FALSE, row.names = FALSE)

plotdf$gene <- factor(plotdf$gene, 
                      levels = names(sort(map_dbl(split(plotdf$nhits, plotdf$gene), 
                                                  median), 
                                          decreasing = FALSE)))
ggplot(plotdf, aes(x=gene, y=nhits)) +
  geom_jitter(height = 0, width = 0.1, alpha=0.2) +
  geom_boxplot(outlier.colour = NA, size=0.5, fill=NA) +
  theme_clean(base_size = 16) +
  theme(plot.background = element_blank(),
        legend.background = element_blank()) +
  # theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  ylab('Number of minority variants found within sample') +
  xlab('Gene') +
  coord_flip()

ggsave("./figures/filtered_minority_variant_count_boxplots.png", width = 10, height = 10)
ggsave("./figures/filtered_minority_variant_count_boxplots.pdf", width = 10, height = 10)

pdf <- all_filt %>% group_by(gene) %>%
  summarise(
    cov_total = sum(cov),
    cov_mean = mean(cov),
    count=n()
  ) %>%
  filter(!grepl("unknown", gene)) %>%
  filter(count<200 & count>1)

plot(pdf$count, pdf$cov_mean)
abline(h=250, col='blue')

summary(lm(cov_mean ~ count, pdf))
```
